version: '2'
services:
  v2ray:
    image: llama_cpp_wrapper:latest
    build:
      context: .
      args:
        HTTPS_PROXY: ""
        BASE_IMAGE: ubuntu:22.04
    restart: always
    privileged: true
    ports:
      - "5000:5000"
    volumes:
      - "./models:/app/models"
      - "./prompts:/app/prompts"
