version: '2'
services:
  v2ray:
    image: llama_cpp_wrapper:latest
    build: .
    restart: always
    privileged: true
    ports:
    - "5000:5000"
    volumes:
    - "./models:/app/models"
    - "./prompts:/app/prompts"
